---
title: "Part 3"
author: "Nick George"
date: "3/21/2018"
output: pdf_document
---
## Nick George and Spencer Louie 
```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=6, fig.height=3)
require(openintro)
require(dplyr)
require(broom)
require(ggplot2)
require(skimr)
kc_data <- read.table("~/MATH158Proj/Part 1/kc_house_data.csv", header=TRUE,
   sep=",")
data("kc_house_data")
kc_data <- kc_data %>% mutate(bedbath = bedrooms + bathrooms)

```

##Introduction
Our regression aims to examine the factors that drive house prices. Our dataset is from the Center for Spatial Data Science, which has collected data on house prices from the King County Washington area from 2014 to 2015 (May). On the left hand side, we have the log of house prices (we decided to log the house prices to correct heteroskedasticity issues) and we have a number of selections for RHS variables. RHS variables of interest include: the square footage of the living space, the lot size, number of floors, whether it is a waterfront property, the condition of the house (as based on King County grading system), and number of bedroom/bathrooms.

##Regression Model:
```{r, echo=FALSE, include=FALSE}
kc_2.lm <- step(lm(log(price)~1, data=kc_data), log(price) ~ (log(sqft_living) + log(sqft_lot) + floors + waterfront + view + condition + grade + bedbath), direction="both", trace=1)
drop1(kc_2.lm, test="F") 


kc_2.lm.resid<- resid(kc_2.lm)

# The code creates a model by finding the best model using AIC Forward-Backward Stepwise selection, then drop1 checks to see if any of the variables are low in significancy. This does not include interaction terms because when I used them the model was huge, so we can add them more selectively later. 


```
The overall model we are looking at is one that include up to the log of living square footage, the log of lot square footage, number of floors, whether the house is waterfront or not, whether the house has a view or not, the condition of the house on a scale, the grade of the house on a scale, and the number of total beds and baths in the house.  
```{r, echo=FALSE}
kc_data_2 <- subset(kc_data, select = c(price, grade, sqft_living, view, condition, sqft_lot, waterfront, bedbath, floors))
kc_data_2 <- kc_data_2 %>% mutate(lprice = log(price), lsqft_living = log(sqft_living), lsqft_lot = log(sqft_lot))
kc_data_3 <- subset(kc_data_2, select = c(lprice, grade, lsqft_living, view, condition, lsqft_lot, waterfront, bedbath, floors))
kc_data_3.matrix <- data.matrix(kc_data_3)
round(cor(kc_data_3.matrix), 2)

#pairs(kc_data_3)
```

[pairs(kc_data_3) The graphs really slow things down so I don't have them included for ease of processing right now.]



The trouble explanatory variables with high correlation are: grade and lsqft_living as well as lsqft_living and bedbath. lsqft_living and lqft_lot are surprisingly not particularly problematic.  

##Interaction Terms:
[We are not currently using interaction terms, however we could. Ones that could be potentially viable in a logical sense are: lsqft_living and floors, capturing so affect on how big each floor is. lsqft_lot and waterfront to try and capture how much waterfront property you have. And finally bedbath and lsqft_living because it could matter how spread out your bed and bath are in the house. However they are already high correlated so I'm not sure how that would affect it. Perhaps an interaction term with lsqft_living and lsqft_lot would be able to capture the effect of having a larger house on a smaller lot or vice versa.]  

```{r, echo=FALSE}
summary(kc_2.lm)
```
An increase in the grade scale by 1 is asscoiated with an 20.1% increase in price. A 1% increase in sqft_living is associated with an .478% increase in price. Having a view is associated with an 8.7% increase in price. An increase in the condition scale by 1 is associated with an 9.5% increase in price. A 1% increase in sqft_lot is associated with an .054% decrease in price. Having a waterfront home is associated with an 37.9% increase in price. Having an extra bedbath is associated with a 1.8% decrease in price  Having an extra floor is associated with a 1.4% decrease in price . All of the variables are significant at .001 significancy level. Some notable surprises are that having extra square footage in your lot is associated with a decrease in price, holding the other variables constant and having another bedroom or bathroom also is associated with a decrease in price holding the other factors constant. Having another floor associated with a decrease in price may seem strange, but makes sense when you consider that overall square footage is being held constant. 


```{r}
kc_2.lm_nested <- lm(log(price) ~ log(sqft_lot) + log(sqft_living) + grade + waterfront + view + condition, data = kc_data)
anova(kc_2.lm_nested, kc_3.lm) #Took out bedbath and floors as they were the least significant in the drop1 F-Test.
```

```{r}
summary(kc_2.lm_nested)$r.squared
summary(kc_2.lm)$r.squared
summary(kc_2.lm_nested)$adj.r.squared
summary(kc_2.lm)$adj.r.squared

```

The nested model explains 59.2% of the variance in prices while the larger model explains 59.3% of the variance. The adjusted values are slightly smaller, but still in the same order. So the larger model definitely explains more, but it is less parsimonious. Since the R^2 change is so slight, we decided to use the nested model because it is more parsimonious and allows to more accrurately pinpoint driving factors of housing prices.  

```{r, echo=FALSE}
kc_2.rstudent <- rstudent(kc_2.lm)
x = (.01/21613)/2
qt(c(x, 1-x), df=21603)
kc_2.rstudent.data <- data.frame(kc_2.rstudent)
```
Above 5.04 and below -5.04 are outliers. There are none that satisfy that requirement. 

```{r, echo=FALSE}
kc_2.hatvalues <- hatvalues(kc_2.lm_nested)
kc_2.hatvalues.data <- data.frame(kc_2.hatvalues)
```
2p/n = 20/21603 = 9.26e-4. This likely too small of a cutoff point, however one observation does seem like a notable outlier though, observation 15871. 

```{r, echo=FALSE}
dffits.kc.data = data.frame(dffits(kc_2.lm_nested), dfbetas(kc_2.lm_nested), cooks.distance(kc_2.lm_nested))
dffits.kc.data_2 = dffits.kc.data[c(15871),]
```

```{r, echo=FALSE}
names(dffits.kc.data_2) <- c("DFFITS", "Intercept", "Grade", "lsq_liv", "View", "Condition", "lsq_lot", "Waterfront", "Cook's")
kable(round(dffits.kc.data_2, 4), align = "c")
```
None of these valus are partiularly out of the ordinary so it does not seem that our data is much influenced by the existence of outliers. 
  
```{r, echo=FALSE}
plot(cooks.distance(kc_2.lm_nested))
```
  
The only Cook's Distance that's significantly higher than the rest is at obesrvation 15871, but even that is still drasticly below 1. Overall it does not seem that any outlier is going to be problematic and so we do not need to look at data that excludes some points. 

##Model Selection:
This model was seleced using a step function going both forward and backward based on AIC. So first the function added a predictor, originally to the null model, that decreased the AIC the most significantly. It would do that again until it ran out of predictors or could no longer add a predictor that reduced AIC. After that it went backward seeing that if it could decrease AIC by removing any predictors. This way you can account for variables that may no longer be significant as others are added, such as through multicollinearity. This process implied that we should use the full possible model noted above. However, using the nested F-test we came to another conclusion, as we put more importance on parsimony than the process implies. So we decided to use the smaller model that did not include the sum of beds and baths as well as the number of floors in the home. 

##Model Interpretation:
```{r}
summary(kc_2.lm_nested)
```
All of our variables are significant at a near 0 significany level. We note that an increase in grade, living square footage, condition, and having a view or being waterfront are associated with increase in price. The only negative effect from a predictor is an increase in lot size leads to a decrease in price. Even in this smaller model we still find that to be the case, which again seems somewhat troublesome. None of these variables are overly correlated with each other with the exception of grade and the log of square foot living space at .74.  

##Condifence Intervals:
```{r}
kc_3_pred.data <- data.frame(grade=8, sqft_living=1200, view=0, condition=3, sqft_lot=7500, waterfront=1)
kc_3_crit_val <- qt(.975, glance(kc_2.lm_nested)$df.resid)
kc_3_gl <- broom::glance(kc_2.lm_nested)
kc_3_sig <- dplyr::pull(kc_gl, sigma)
kc_3_pred <- broom::augment(kc_2.lm_nested, newdata=kc_3_pred.data, typepredict = "predict") %>% mutate(.se.pred = sqrt(kc_3_sig^2 + .se.fit^2)) %>% mutate(lower_PI = .fitted - crit_val*.se.pred, upper_PI = .fitted + crit_val*.se.pred, lower_CI = .fitted - crit_val*.se.fit, upper_CI = .fitted + crit_val * .se.fit)
kc_3_pred 
```
PI: 12.4801 14.00802
CI: 13.18641  13.30171
```{r}
exp(12.4801)
exp(14.00802)
exp(13.18641)
exp(13.30171)
```
PI: 263050.2 1212288
CI: 533071.1 598217.7
95% of prices for a home with grade 8, 1200 living square footage, no view, a condition rating of 3, a 7500 square foot lot and a awater front view would be between 263,050 and 1,212,288. We are 95% confident that the average price of a home with those specifications would be between 533,071 and 598,217. 



##Partial Coefficent of Determination:
```{r, echo=FALSE}
library(rsq) #Will likely need to install this package. 
rsq.partial(kc_2.lm_nested, lm(log(price) ~ log(sqft_lot) + waterfront + view + condition + grade , data=kc_data), adj=FALSE, type=c("v"))$partial.rsq
rsq.partial(kc_2.lm_nested, lm(log(price) ~ (log(sqft_living) + waterfront + view + condition + grade), data=kc_data), adj=FALSE, type=c("v"))$partial.rsq
rsq.partial(kc_2.lm_nested, lm(log(price) ~ (log(sqft_living) + log(sqft_lot) +  view + condition + grade), data=kc_data), adj=FALSE, type=c("v"))$partial.rsq
rsq.partial(kc_2.lm_nested, lm(log(price) ~ (log(sqft_living) + log(sqft_lot) + waterfront + condition + grade), data=kc_data), adj=FALSE, type=c("v"))$partial.rsq
rsq.partial(kc_2.lm_nested, lm(log(price) ~ (log(sqft_living) + log(sqft_lot) + waterfront + view + grade), data=kc_data), adj=FALSE, type=c("v"))$partial.rsq
rsq.partial(kc_2.lm_nested, lm(log(price) ~ (log(sqft_living) + log(sqft_lot) + waterfront + view + condition), data=kc_data), adj=FALSE, type=c("v"))$partial.rsq
```
The higher partial coefficients of determination belong to the log of living square footage and grade, with .102 and .172 respectively.  The partial coeffienct of determination measures the the marginal contribution of the variables when the others are included in the model. So the log of living square footage has a marginal effect of .10 and grade has a marginal contribution of .17. Neither are excesively large so neither is exclusively driving our model, however their effects are clearly important more so than the other predictors included.  

##Summary
We started by finding a model through the forwards-backwards selection with an AIC criterion. Through this we landed on a model with square footage of the lot and of the living space, its grade, its quality of view, whether it was a waterfront view, and its condition. Through a nested F test we eliminated the number of floors and the number of bedrooms/bathrooms. Through ANOVA, residual plots, and diagnostics, we see that the regression is well-fitted and not unduly influenced by extreme X or Y variables.

#Aside